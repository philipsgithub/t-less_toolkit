{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "# Author: Tomas Hodan (hodantom@cmp.felk.cvut.cz)\n",
    "# Center for Machine Perception, Czech Technical University in Prague\n",
    "\n",
    "# A script to render 3D object models into the test images. The models are\n",
    "# rendered at the ground truth 6D poses that are provided with the test images.\n",
    "# The visualizations are saved into the folder specified by \"output_dir\".\n",
    "\n",
    "from pytless import inout, misc\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "import camtools, open3d as o3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_ids = [1] # Choose which scene_ids to render. Eg. range(1, 21)\n",
    "device = 'canon' # options: 'primesense' (720x540), 'kinect' (720x540), 'canon' (2560x1920)\n",
    "model_type = 'cad' # options: 'cad', 'reconst'\n",
    "im_step = 100 # Consider every im_step-th image\n",
    "\n",
    "# Path to the T-LESS dataset.\n",
    "# Which you can download using the t-less_download.py script. \n",
    "data_path = '../t-less_v2'\n",
    "\n",
    "# Path to the folder in which the images produced by this script will be saved\n",
    "output_dir = os.path.join(data_path, 'output_check_poses_test_imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the elements of the T-LESS dataset\n",
    "model_path_mask = os.path.join(data_path, 'models_' + model_type, 'obj_{:02d}.ply')\n",
    "scene_info_path_mask = os.path.join(data_path, 'test_{}', '{:02d}', 'info.yml')\n",
    "scene_gt_path_mask = os.path.join(data_path, 'test_{}', '{:02d}', 'gt.yml')\n",
    "rgb_path_mask = os.path.join(data_path, 'test_{}', '{:02d}', 'rgb', '{:04d}.{}')\n",
    "depth_path_mask = os.path.join(data_path, 'test_{}', '{:02d}', 'depth', '{:04d}.png')\n",
    "rgb_ext = {'primesense': 'png', 'kinect': 'png', 'canon': 'jpg'}\n",
    "obj_colors_path = os.path.join('data', 'obj_rgb.txt')\n",
    "vis_rgb_path_mask = os.path.join(output_dir, '{:02d}_{}_{}_{:04d}_rgb.png')\n",
    "vis_depth_path_mask = os.path.join(output_dir, '{:02d}_{}_{}_{:04d}_depth_diff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload pytless modules to reflect possible changes during development\n",
    "import importlib\n",
    "importlib.reload(inout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceafcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc.ensure_dir(output_dir)\n",
    "obj_colors = inout.load_colors(obj_colors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580af770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.__version__\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "img = Image.new('RGB', (640, 480), (73, 109, 137))\n",
    "#img = Image.fromarray(np.zeros((480, 640)))\n",
    "color = (255, 255, 255)\n",
    "rect = [408, 239, 118, 93]\n",
    "draw = ImageDraw.Draw(img)\n",
    "# If 'TypeError: must be real number, not tuple' then the image is grayscale!\n",
    "draw.rectangle((rect[0], rect[1], rect[0] + rect[2], rect[1] + rect[3]), outline=color, fill=color)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = 1\n",
    "\n",
    "# Load info about the test images (including camera parameters etc.)\n",
    "scene_info_path = scene_info_path_mask.format(device, scene_id)\n",
    "scene_info = inout.load_info(scene_info_path)\n",
    "\n",
    "scene_gt_path = scene_gt_path_mask.format(device, scene_id)\n",
    "scene_gt = inout.load_gt(scene_gt_path)\n",
    "\n",
    "# Load models of objects present in the scene\n",
    "scene_obj_ids = set()\n",
    "for gt in scene_gt[0]:\n",
    "    scene_obj_ids.add(gt['obj_id'])\n",
    "models = {}\n",
    "for scene_obj_id in scene_obj_ids:\n",
    "    model_path = model_path_mask.format(scene_obj_id)\n",
    "    models[scene_obj_id] = inout.load_ply(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_obj_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef286ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[25].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[25][\"pts\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc637522",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_id, im_info = list(scene_info.items())[0]\n",
    "im_id, im_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('scene: ' + str(scene_id) + ', device: ' + device + ', im_id: ' + str(im_id))\n",
    "\n",
    "# Get intrinsic camera parameters\n",
    "K = im_info['cam_K']\n",
    "print(f\"cx, cy: {K[0,2]}, {K[1,2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_path = rgb_path_mask.format(device, scene_id, im_id, rgb_ext[device])\n",
    "rgb = imageio.v2.imread(rgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a43c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_gt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384787bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_gt[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_simple(model, im_size, K, R, t, z_in_view_space=True):\n",
    "    # Create mesh\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(model['pts'])\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(model['faces'])\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    # Set up renderer\n",
    "    renderer = o3d.visualization.rendering.OffscreenRenderer(im_size[0], im_size[1])\n",
    "\n",
    "    # Set up material\n",
    "    material = o3d.visualization.rendering.MaterialRecord()\n",
    "    material.shader = \"defaultLit\"\n",
    "\n",
    "    renderer.scene.add_geometry(\"mesh\", mesh, material)\n",
    "\n",
    "    # Set camera intrinsics\n",
    "    renderer.setup_camera(K, np.vstack([np.hstack([R, t]), np.array([0,0,0,1])]), im_size[0], im_size[1])\n",
    "\n",
    "    # Render\n",
    "    rgb = np.asarray(renderer.render_to_image()) # RGB image, H x W x 3, float, [0.0, 1.0]\n",
    "    depth = np.asarray(renderer.render_to_depth_image(z_in_view_space=z_in_view_space)) # Depth image, H x W, float, in meters\n",
    "    mask = depth < np.inf\n",
    "\n",
    "    return rgb, depth, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = (rgb.shape[1], rgb.shape[0])\n",
    "vis_rgb = np.zeros(rgb.shape, float)\n",
    "\n",
    "rendered_depths = []\n",
    "rendered_masks = []\n",
    "rendered_obj_ids = []\n",
    "\n",
    "for gt in scene_gt[im_id]:\n",
    "    model = models[gt['obj_id']]\n",
    "    R = gt['cam_R_m2c']\n",
    "    t = gt['cam_t_m2c']\n",
    "    surf_color = obj_colors[gt['obj_id'] - 1]\n",
    "    print(f\"surf_color: {surf_color}, obj_id: {gt['obj_id']}, model_type: {model}, K: {K}, R: {R}, t: {t}\")\n",
    "\n",
    "    # ren_rgb = renderer.render(model, im_size, K, R, t,\n",
    "    #                             surf_color=surf_color, mode='rgb')\n",
    "    ren_rgb, ren_depth, ren_mask = render_simple(model, im_size, K, R, t,)\n",
    "\n",
    "    # check for empty array\n",
    "    if ren_rgb.shape == (0,):\n",
    "        print(\"EMPTY RENDERING!\")\n",
    "    else:\n",
    "        print(ren_rgb.shape)\n",
    "\n",
    "    rendered_depths.append(ren_depth)\n",
    "    rendered_masks.append(ren_mask)\n",
    "    rendered_obj_ids.append(gt['obj_id'])\n",
    "\n",
    "    # Draw the bounding box of the object\n",
    "    #print(gt['obj_bb'])\n",
    "    #ren_rgb = misc.draw_rect(ren_rgb, gt['obj_bb'])\n",
    "\n",
    "    #vis_rgb += 0.7 * ren_rgb.astype(float)\n",
    "\n",
    "acc_depth = np.zeros(rgb.shape[:2], float) + np.inf\n",
    "for ren_depth, ren_mask in zip(rendered_depths, rendered_masks):\n",
    "    acc_depth[ren_mask] = np.minimum(acc_depth[ren_mask], ren_depth[ren_mask])\n",
    "acc_depth[acc_depth == np.inf] = 0\n",
    "\n",
    "object_masks = np.zeros(rgb.shape, int)\n",
    "for idx, ren_mask in enumerate(rendered_masks):\n",
    "    object_masks[(acc_depth <= rendered_depths[idx]) & (ren_mask == True)] = np.array(obj_colors[rendered_obj_ids[idx] - 1]) * 255\n",
    "    print(f\"Using object id {rendered_obj_ids[idx]} with color {obj_colors[rendered_obj_ids[idx] - 1]}\")\n",
    "\n",
    "plt.imshow(object_masks)#, cmap='gray', vmin=0, vmax=len(rendered_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e17bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(rgb / 255 * 0.3 + 0.7 * object_masks / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62514b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a56394",
   "metadata": {},
   "outputs": [],
   "source": [
    "K[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize current model and camera pose in model coordinate system\n",
    "\n",
    "T = np.eye(4)\n",
    "\n",
    "# invert R, t to get camera to model transformation\n",
    "T[:3, :3] = R # np.linalg.inv(R)\n",
    "T[:3, 3] = (t).flatten() / 1000.0  # Convert mm to meters\n",
    "camera_frustums = camtools.camera.create_camera_frustums([K], [T], size=1.)\n",
    "\n",
    "model_mesh = o3d.geometry.TriangleMesh()\n",
    "model_mesh.vertices = o3d.utility.Vector3dVector(models[gt['obj_id']]['pts']/1000)\n",
    "model_mesh.triangles = o3d.utility.Vector3iVector(models[gt['obj_id']]['faces'])\n",
    "model_mesh.compute_vertex_normals()\n",
    "\n",
    "# draw world origin\n",
    "axis_length = 0.1\n",
    "world_origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=axis_length, origin=[0,0,0])\n",
    "model_pcls = []#o3d.geometry.PointCloud(o3d.utility.Vector3dVector(model['pts']/1000+ np.array([0,0,idx+1]))) for idx, model in enumerate(models.values())]\n",
    "\n",
    "o3d.visualization.draw_geometries([camera_frustums, world_origin, model_mesh, o3d.geometry.PointCloud(o3d.utility.Vector3dVector(model['pts']/1000))],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_id in scene_ids:\n",
    "\n",
    "    # Load info about the test images (including camera parameters etc.)\n",
    "    scene_info_path = scene_info_path_mask.format(device, scene_id)\n",
    "    scene_info = inout.load_info(scene_info_path)\n",
    "\n",
    "    scene_gt_path = scene_gt_path_mask.format(device, scene_id)\n",
    "    scene_gt = inout.load_gt(scene_gt_path)\n",
    "\n",
    "    # Load models of objects present in the scene\n",
    "    scene_obj_ids = set()\n",
    "    for gt in scene_gt[0]:\n",
    "        scene_obj_ids.add(gt['obj_id'])\n",
    "    models = {}\n",
    "    for scene_obj_id in scene_obj_ids:\n",
    "        model_path = model_path_mask.format(scene_obj_id)\n",
    "        models[scene_obj_id] = inout.load_ply(model_path)\n",
    "\n",
    "    for im_id, im_info in scene_info.items():\n",
    "        if im_id % im_step != 0:\n",
    "            continue\n",
    "        print('scene: ' + str(scene_id) + ', device: ' + device + ', im_id: ' + str(im_id))\n",
    "\n",
    "        # Get intrinsic camera parameters\n",
    "        K = im_info['cam_K']\n",
    "\n",
    "        # Visualization #1\n",
    "        #-----------------------------------------------------------------------\n",
    "        # Load RGB image\n",
    "        rgb_path = rgb_path_mask.format(device, scene_id, im_id, rgb_ext[device])\n",
    "        rgb = imageio.v2.imread(rgb_path)\n",
    "\n",
    "        im_size = (rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        rendered_depths = []\n",
    "        rendered_masks = []\n",
    "        rendered_obj_ids = []\n",
    "\n",
    "        #vis_rgb = np.zeros(rgb.shape, float)\n",
    "        for gt in scene_gt[im_id]:\n",
    "            model = models[gt['obj_id']]\n",
    "            R = gt['cam_R_m2c']\n",
    "            t = gt['cam_t_m2c']\n",
    "            surf_color = obj_colors[gt['obj_id'] - 1]\n",
    "            print(f\"surf_color: {surf_color}, obj_id: {gt['obj_id']}, model_type: {model}, K: {K}, R: {R}, t: {t}\")\n",
    "            ren_rgb, ren_depth, ren_mask = render_simple(model, im_size, K, R, t,)\n",
    "\n",
    "            # check for empty array\n",
    "            if ren_rgb.shape == (0,):\n",
    "                print(\"EMPTY RENDERING!\")\n",
    "            else:\n",
    "                print(ren_rgb.shape)\n",
    "\n",
    "            rendered_depths.append(ren_depth)\n",
    "            rendered_masks.append(ren_mask)\n",
    "            rendered_obj_ids.append(gt['obj_id'])\n",
    "\n",
    "            # Draw the bounding box of the object\n",
    "            #print(gt['obj_bb'])\n",
    "            #ren_rgb = misc.draw_rect(ren_rgb, gt['obj_bb'])\n",
    "\n",
    "            #vis_rgb += 0.7 * ren_rgb.astype(float)\n",
    "\n",
    "        acc_depth = np.zeros(rgb.shape[:2], float) + np.inf\n",
    "        for ren_depth, ren_mask in zip(rendered_depths, rendered_masks):\n",
    "            acc_depth[ren_mask] = np.minimum(acc_depth[ren_mask], ren_depth[ren_mask])\n",
    "        acc_depth[acc_depth == np.inf] = 0\n",
    "\n",
    "        object_masks = np.zeros(rgb.shape, int)\n",
    "        for idx, ren_mask in enumerate(rendered_masks):\n",
    "            object_masks[(acc_depth >= rendered_depths[idx]) & (ren_mask == True)] = np.array(obj_colors[rendered_obj_ids[idx] - 1]) * 255\n",
    "            print(f\"Using object id {rendered_obj_ids[idx]} with color {obj_colors[rendered_obj_ids[idx] - 1]}\")\n",
    "\n",
    "        plt.imshow(object_masks)#, cmap='gray', vmin=0, vmax=len(rendered_masks))\n",
    "\n",
    "        # Save the visualization\n",
    "        vis_rgb = 0.6 * object_masks + 0.4 * rgb\n",
    "        vis_rgb_path = vis_rgb_path_mask.format(scene_id, device, model_type, im_id)\n",
    "        imageio.imwrite(vis_rgb_path, vis_rgb.astype(np.uint8))\n",
    "\n",
    "        # Visualization #2\n",
    "        #-----------------------------------------------------------------------\n",
    "        if False and device != 'canon':\n",
    "            # Load depth image\n",
    "            depth_path = depth_path_mask.format(device, scene_id, im_id, rgb_ext[device])\n",
    "            depth = imageio.v2.imread(depth_path)  # Unit: 0.1 mm\n",
    "            depth = depth.astype(float) * 0.1  # Convert to mm\n",
    "\n",
    "            # Render the objects at the ground truth poses\n",
    "            im_size = (depth.shape[1], depth.shape[0])\n",
    "            ren_depth = np.zeros(depth.shape, float)\n",
    "            for gt in scene_gt[im_id]:\n",
    "                model = models[gt['obj_id']]\n",
    "                R = gt['cam_R_m2c']\n",
    "                t = gt['cam_t_m2c']\n",
    "\n",
    "                # Render the current object\n",
    "                ren_depth_obj = renderer.render(model, im_size, K, R, t, mode='depth')\n",
    "\n",
    "                # Add to the final depth map only the parts of the surface that\n",
    "                # are closer than the surfaces rendered before\n",
    "                visible_mask = np.logical_or(ren_depth == 0, ren_depth_obj < ren_depth)\n",
    "                mask = np.logical_and(ren_depth_obj != 0, visible_mask)\n",
    "                ren_depth[mask] = ren_depth_obj[mask].astype(float)\n",
    "\n",
    "            # Calculate the depth difference at pixels where both depth maps\n",
    "            # are valid\n",
    "            valid_mask = (depth > 0) * (ren_depth > 0)\n",
    "            depth_diff = valid_mask * (depth - ren_depth.astype(float))\n",
    "\n",
    "            # Save the visualization\n",
    "            vis_depth_path = vis_depth_path_mask.format(scene_id, device,\n",
    "                                                        model_type, im_id)\n",
    "            plt.matshow(depth_diff)\n",
    "            plt.title('captured - rendered depth [mm]')\n",
    "            plt.colorbar()\n",
    "            plt.savefig(vis_depth_path)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090bbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
